import os
import json
import uuid
import uvicorn
import asyncio
from urllib.parse import urlparse
from fastapi import FastAPI
from dotenv import load_dotenv
from datetime import datetime, timezone

from a2a.server.apps.jsonrpc.fastapi_app import A2AFastAPIApplication
from a2a.server.agent_execution import AgentExecutor
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore
from a2a.server.agent_execution.context import RequestContext
from a2a.types import (
    TaskStatusUpdateEvent,
    TaskArtifactUpdateEvent,
    TaskStatus,
    TaskState,
    Artifact,
    Message,
    TextPart,
    Part,
)
from a2a.types import AgentCard

from openai import AsyncOpenAI

# Load environment variables from .env file
load_dotenv()

# Initialize OpenAI client (optional)
has_openai_key = (
    os.getenv("OPENAI_API_KEY") and os.getenv("OPENAI_API_KEY") != "dummy-key"
)
openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY") or "dummy-key")

# Load agent card from .agent-card.json
with open(".agent-card.json", "r") as f:
    agent_card_dict = json.load(f)

# Override URL from environment if present
if os.getenv("AGENT_URL"):
    agent_card_dict["url"] = os.getenv("AGENT_URL")

# Ensure capabilities are set
if "capabilities" not in agent_card_dict:
    agent_card_dict["capabilities"] = {}
agent_card_dict["capabilities"]["streaming"] = True
agent_card_dict["capabilities"]["pushNotifications"] = True

# Convert dict to AgentCard object
agent_card = AgentCard.model_validate(agent_card_dict)


class Executor(AgentExecutor):
    """
    Implements the core agent logic for the basic template.
    Demonstrates:
    1. Task creation and management (A2A Task Protocol)
    2. Streaming status updates (submitted -> working -> completed)
    3. Generating and sending Artifacts
    4. Handling Cancellation
    """
    
    def __init__(self):
        self.cancelled_tasks = set()

    async def execute(
        self, request_context: RequestContext, event_bus
    ):
        task_id = request_context.task_id
        context_id = request_context.context_id
        user_message = request_context.message
        task = request_context.current_task

        try:
            # 1. Initialize Task if needed
            if not task:
                initial_task = TaskStatusUpdateEvent(
                    kind="status-update",
                    taskId=task_id,
                    contextId=context_id,
                    status=TaskStatus(
                        state=TaskState.submitted,
                        timestamp=datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                    ),
                    final=False,
                )
                await event_bus.enqueue_event(initial_task)

            user_text = next(
                (p.root.text for p in user_message.parts if p.root.kind == "text"), ""
            )
            print(f'[{task_id}] üì© Message received: "{user_text}"')

            # 2. Update Status to 'working'

            working_update = TaskStatusUpdateEvent(
                kind="status-update",
                taskId=task_id,
                contextId=context_id,
                status=TaskStatus(
                    state=TaskState.working,
                    timestamp=datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                ),
                final=False,
            )
            await event_bus.enqueue_event(working_update)

            # Check for cancellation
            if task_id in self.cancelled_tasks:
                return await self._handle_cancelled(task_id, context_id, event_bus)

            response_text = ""
            
            if has_openai_key:
                try:
                    print(f"[{task_id}] üß† Calling OpenAI to generate response...")
                    
                    # Send an artifact to show "thinking"
                    await event_bus.enqueue_event(
                        TaskArtifactUpdateEvent(
                            kind="artifact-update",
                            taskId=task_id,
                            contextId=context_id,
                            artifact=Artifact(
                                artifactId=f"thought-{int(datetime.now(timezone.utc).timestamp())}",
                                name="Thought Process",
                                parts=[Part(root=TextPart(text="Analyzing your request..."))],
                            ),
                        )
                    )

                    response = await openai_client.chat.completions.create(
                        model="gpt-4-turbo",
                        messages=[
                            {
                                "role": "system",
                                "content": f"You are a helpful assistant named {agent_card.name}.",
                            },
                            {"role": "user", "content": user_text},
                        ],
                        # We could enable streaming here and publish partial updates if A2A supports it
                        # For now, we await the full response to keep it simple, but check cancellation
                    )
                    
                    if task_id in self.cancelled_tasks:
                        return await self._handle_cancelled(task_id, context_id, event_bus)
                        
                    response_text = response.choices[0].message.content
                    
                except Exception as e:
                    print(f"[{task_id}]  OpenAI error: {e}")
                    response_text = self._generate_fallback_response(user_text)
            else:
                # Simulate work
                print(f"[{task_id}] ü§ñ Generating fallback response (simulating work)...")
                for _ in range(10): # 1 second delay split into checks
                    if task_id in self.cancelled_tasks:
                        return await self._handle_cancelled(task_id, context_id, event_bus)
                    await asyncio.sleep(0.1)
                    
                response_text = self._generate_fallback_response(user_text)

            if task_id in self.cancelled_tasks:
                return await self._handle_cancelled(task_id, context_id, event_bus)

            # 3. Publish Final Response
            response_message = Message(
                kind="message",
                messageId=str(uuid.uuid4()),
                role="agent",
                parts=[Part(root=TextPart(text=response_text or ""))],
                contextId=context_id,
            )
            await event_bus.enqueue_event(response_message)

            # 4. Mark Task as Completed
            completed_update = TaskStatusUpdateEvent(
                kind="status-update",
                taskId=task_id,
                contextId=context_id,
                status=TaskStatus(
                    state=TaskState.completed,
                    timestamp=datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                ),
                final=True,
            )
            await event_bus.enqueue_event(completed_update)
            print(f"[{task_id}] üì§ Response sent and task completed.")

        except Exception as e:
            print(f"[{task_id}] üí• Error during execution: {e}")
            error_message = Message(
                kind="message",
                messageId=str(uuid.uuid4()),
                role="agent",
                parts=[
                    Part(root=TextPart(text=f"I encountered an error processing your request: {e}"))
                ],
                contextId=context_id,
            )
            await event_bus.enqueue_event(error_message)
            # Mark as failed
            await event_bus.enqueue_event(
                TaskStatusUpdateEvent(
                    kind="status-update",
                    taskId=task_id,
                    contextId=context_id,
                    status=TaskStatus(
                        state=TaskState.failed,
                        timestamp=datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                    ),
                    final=True,
                )
            )
        finally:
            # Clean up cancellation set
            if task_id in self.cancelled_tasks:
                self.cancelled_tasks.remove(task_id)
            await event_bus.close()

    async def _handle_cancelled(self, task_id, context_id, event_bus):
        print(f"[{task_id}] üõë Execution aborted due to cancellation.")
        await event_bus.enqueue_event(
            TaskStatusUpdateEvent(
                kind="status-update",
                taskId=task_id,
                contextId=context_id,
                status=TaskStatus(
                    state=TaskState.canceled,
                    timestamp=datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                ),
                final=True,
            )
        )
        return

    def _generate_fallback_response(self, user_text: str) -> str:
        lower_text = user_text.lower()
        if "hello" in lower_text or "hi" in lower_text:
            return f"Hello! I'm {agent_card.name}, your AI assistant. How can I help you today?"
        if "help" in lower_text:
            return "I'm here to help! For better responses, configure an OpenAI API key."
        if "what" in lower_text and "do" in lower_text:
            return "I am an A2A-compliant AI agent. Try asking me questions!"
        return f'You said: "{user_text}". I am in simple mode. Configure OPENAI_API_KEY for AI responses.'

    async def cancel(self, task_id: str, event_bus):
        print(f"[{task_id}] üõë Task cancellation requested")
        self.cancelled_tasks.add(task_id)
        # Note: The execute loop picks up this flag. 
        # We don't publish the 'canceled' event here to avoid race conditions,
        # relying on execute() to publish it when it exits.
        



# Initialize A2A Server
app = FastAPI()
agent_executor = Executor()
task_store = InMemoryTaskStore()
request_handler = DefaultRequestHandler(
    task_store=task_store, agent_executor=agent_executor
)
app_builder = A2AFastAPIApplication(agent_card=agent_card, http_handler=request_handler)
app_builder.add_routes_to_app(app, agent_card_url="/.well-known/agent-card.json")

if __name__ == "__main__":
    port_str = os.environ.get("PORT")
    if port_str:
        port = int(port_str)
    else:
        parsed_url = urlparse(agent_card.url)
        port = parsed_url.port or 8082

    skill_names = ", ".join([s.id for s in agent_card.skills or []])

    print(f"üöÄ A2A Agent \"{agent_card.name}\" starting on port {port}")
    print(f"üìã Agent Card: http://localhost:{port}/.well-known/agent-card.json")
    print(f"üîß Skills: {skill_names}")
    print("\nüí° Try sending a message:")
    print("   - 'Hello'")
    print("   - 'What can you do?'\n")
    if not has_openai_key:
        print("‚ö†Ô∏è  No OPENAI_API_KEY found - running in simple mode")
        print("   Set OPENAI_API_KEY in .env for AI-powered responses\n")

    uvicorn.run(app, host="0.0.0.0", port=port)
