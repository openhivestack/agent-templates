import os
import json
import uuid
import uvicorn
from urllib.parse import urlparse
from fastapi import FastAPI
from dotenv import load_dotenv


from a2a.server.apps.jsonrpc.fastapi_app import A2AFastAPIApplication
from a2a.server.agent_execution import AgentExecutor
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore
from a2a.server.agent_execution.context import RequestContext
from a2a.types import AgentCard

from openai import AsyncOpenAI

# Load environment variables from .env file
load_dotenv()

# Initialize OpenAI client (optional)
has_openai_key = (
    os.getenv("OPENAI_API_KEY") and os.getenv("OPENAI_API_KEY") != "dummy-key"
)
openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Load agent card from .agent-card.json
with open(".agent-card.json", "r") as f:
    agent_card_dict = json.load(f)

# Override URL from environment if present
if os.getenv("AGENT_URL"):
    agent_card_dict["url"] = os.getenv("AGENT_URL")

# Convert dict to AgentCard object
agent_card = AgentCard.model_validate(agent_card_dict)


class Executor(AgentExecutor):
    """
    Implements the core agent logic for the basic template.
    """

    async def execute(
        self, request_context: RequestContext, event_bus
    ):
        task_id = request_context.task_id
        context_id = request_context.context_id
        user_message = request_context.user_message

        try:
            user_text = next(
                (p["text"] for p in user_message["parts"] if p["kind"] == "text"), ""
            )
            print(f'[{task_id}] üì© Message received: "{user_text}"')

            response_text = ""
            if has_openai_key:
                try:
                    print(f"[{task_id}] üß† Calling OpenAI to generate response...")
                    response = await openai_client.chat.completions.create(
                        model="gpt-4-turbo",
                        messages=[
                            {
                                "role": "system",
                                "content": f"You are a helpful assistant named {agent_card.name}.",
                            },
                            {"role": "user", "content": user_text},
                        ],
                    )
                    response_text = response.choices[0].message.content
                except Exception as e:
                    print(f"[{task_id}]  OpenAI error: {e}")
                    response_text = self._generate_fallback_response(user_text)
            else:
                print(f"[{task_id}] ü§ñ Generating fallback response...")
                response_text = self._generate_fallback_response(user_text)

            response_message = {
                "kind": "message",
                "messageId": str(uuid.uuid4()),
                "role": "agent",
                "parts": [{"kind": "text", "text": response_text or ""}],
                "contextId": context_id,
            }

            event_bus.publish(response_message)
            print(f"[{task_id}] üì§ Response sent.")

        except Exception as e:
            print(f"[{task_id}] üí• Error during execution: {e}")
            error_message = {
                "kind": "message",
                "messageId": str(uuid.uuid4()),
                "role": "agent",
                "parts": [
                    {
                        "kind": "text",
                        "text": f"I encountered an error processing your request: {e}",
                    }
                ],
                "contextId": context_id,
            }
            event_bus.publish(error_message)
        finally:
            event_bus.finished()

    def _generate_fallback_response(self, user_text: str) -> str:
        lower_text = user_text.lower()
        if "hello" in lower_text or "hi" in lower_text:
            return f"Hello! I'm {agent_card.name}, your AI assistant. How can I help you today?"
        if "help" in lower_text:
            return "I'm here to help! For better responses, configure an OpenAI API key."
        if "what" in lower_text and "do" in lower_text:
            return "I am an A2A-compliant AI agent. Try asking me questions!"
        return f'You said: "{user_text}". I am in simple mode. Configure OPENAI_API_KEY for AI responses.'

    async def cancel(self, task_id: str, event_bus):
        print(f"[{task_id}] Task cancellation requested")


# Initialize A2A Server
app = FastAPI()
agent_executor = Executor()
task_store = InMemoryTaskStore()
request_handler = DefaultRequestHandler(
    task_store=task_store, agent_executor=agent_executor
)
app_builder = A2AFastAPIApplication(agent_card=agent_card, http_handler=request_handler)
app_builder.add_routes_to_app(app, agent_card_url=str(".agent-card.json"))

if __name__ == "__main__":
    port_str = os.environ.get("PORT")
    if port_str:
        port = int(port_str)
    else:
        parsed_url = urlparse(agent_card.url)
        port = parsed_url.port or 8082

    skill_names = ", ".join([s.id for s in agent_card.skills or []])

    print(f"üöÄ A2A Agent \"{agent_card.name}\" starting on port {port}")
    print(f"üìã Agent Card: http://localhost:{port}/.well-known/agent-card.json")
    print(f"üîß Skills: {skill_names}")
    print("\nüí° Try sending a message:")
    print("   - 'Hello'")
    print("   - 'What can you do?'\n")
    if not has_openai_key:
        print("‚ö†Ô∏è  No OPENAI_API_KEY found - running in simple mode")
        print("   Set OPENAI_API_KEY in .env for AI-powered responses\n")

    uvicorn.run(app, host="0.0.0.0", port=port)
